<!DOCTYPE html>
<html>
  <!-- Html Head Tag-->
  <head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="Echo Meng">
  <!-- Open Graph Data -->
  <meta property="og:title" content="Python爬虫入门"/>
  <meta property="og:description" content="Can&#39;t help but code." />
  <meta property="og:site_name" content="Echo Meng&#39;s Blog"/>
  <meta property="og:type" content="article" />
  <meta property="og:image" content="http://www.echomeng.cn"/>
  
    <link rel="alternate" href="/atom.xml" title="Echo Meng&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  

  <!-- Site Title -->
  <title>Echo Meng's Blog</title>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <!-- Custom CSS -->
  
  <link rel="stylesheet" href="/css/style.light.css">

  <!-- Google Analytics -->
  

</head>

  <body>
    <!-- Page Header -->


<header class="site-header header-background" style="background-image: url(/img/default-banner-dark.jpg)">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="page-title with-background-image">
          <p class="title">Python爬虫入门</p>
          <p class="subtitle"></p>
        </div>
        <div class="site-menu with-background-image">
          <ul>
            
              <li>
                <a href="/">
                  
                  Home
                  
                </a>
              </li>
            
              <li>
                <a href="/archives">
                  
                  Archives
                  
                </a>
              </li>
            
              <li>
                <a href="https://github.com/EchoMeng/">
                  
                  Github
                  
                </a>
              </li>
            
              <li>
                <a href="mailto:mengxiangxxa@163.com">
                  
                  Email
                  
                </a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>

<article>
  <div class="container typo">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-info text-muted">
          
            <!-- Author -->
            <span class="author info">By Echo Meng</span>
          
          <!-- Date -->
          <span class="date-time info">On
            <span class="date">2018-12-09</span>
            <span class="time">11:01:22</span>
          </span>
          
          <!--  Categories  -->
            <span class="categories info">Under 

<a href="/categories/技术/">技术</a>
</span>
          
        </div>
        <!-- Tags -->
        
          <div class="post-tags text-muted">
            Tags: 

<a class="tag" href="/tags/Python/">#Python</a> <a class="tag" href="/tags/爬虫/">#爬虫</a>


          </div>
        
        <!-- Post Main Content -->
        <div class="post-content">
            
              <div id="toc" class="toc-article">
                <strong class="toc-title">文章目录</strong>
              <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Python爬虫架构"><span class="toc-text">Python爬虫架构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#搭建开发环境"><span class="toc-text">搭建开发环境</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#动手前需要知道"><span class="toc-text">动手前需要知道</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#开始动手了！"><span class="toc-text">开始动手了！</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#糗百"><span class="toc-text">糗百</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#百度贴吧"><span class="toc-text">百度贴吧</span></a></li></ol></li></ol>
              </div>
              
          <p>怎么使用爬虫抓数据呢？</p>
<a id="more"></a>
<h1 id="Python爬虫架构"><a href="#Python爬虫架构" class="headerlink" title="Python爬虫架构"></a>Python爬虫架构</h1><p><a href="http://www.runoob.com/w3cnote/python-spider-intro.html" target="_blank" rel="noopener">Python爬虫介绍</a><br><a href="https://zhuanlan.zhihu.com/p/21479334" target="_blank" rel="noopener">如何学习python爬虫</a></p>
<p>Python爬虫架构主要有五个部分构成，分别是调度器，URL管理器，网页下载器，网页解析器，应用程序（爬取的有价值数据）。</p>
<ul>
<li>调度器：相当于一台电脑的CPU，负责调度URL管理器、下载器、解析器之间的协调工作。</li>
<li>URL管理器：包括待爬取的URL地址和已爬取的URL地址，防止重复抓取URL和循环抓取，实现URL管理器主要用三种方式，通过内存、数据库、缓存数据库来实现。</li>
<li>网页下载器：通过传入一个URL地址来下载网页，将网页转换成一个字符串，网页下载器有urllib2(Python官方基础模块)，包括需要登陆、代理、和cookie，requests（第三方包）。</li>
<li>网页解析器：将一个网页字符串进行解析，可以按照我们的要求来提取出游泳的信息，也可以根据DOM树的解析方式来解析。网页解析器有正则表达式、html.parser、beautifulsoup、lxml，后三者都是使用DOM树的方式进行解析的。<ul>
<li>正则表达式：直观，将网页转成字符串通过模糊匹配的方式来提取有价值的信息，当文档比较复杂的时候，该方法提供数据的时候会非常困难。</li>
<li>html.parser：Python自带。</li>
<li>beautifulsoup：第三方插件，可以使用Python自带的html.parser解析，也可以使用lxml进行解析，更加强大。</li>
<li>lxml：第三方插件，可以解析xml和HTML。</li>
</ul>
</li>
<li>应用程序：就是从网页中提取的有用数据组组成的一个应用。</li>
</ul>
<h1 id="搭建开发环境"><a href="#搭建开发环境" class="headerlink" title="搭建开发环境"></a>搭建开发环境</h1><p>在Mac上运行Python3还是遇到了一些问题的，这里mark以下：</p>
<ul>
<li>在Mac上存在同时运行Python2和Python3的情况，所以对应的处理命令应该是<code>python3</code>，<code>pip3</code></li>
<li>一些依赖的第三方框架需要使用<code>pip3 install xxx</code>命令安装</li>
<li>如果出现<code>sudo: pip: command not found</code>的错误，两个问题：第一，要使用<code>pip3</code>命令；第二，<code>pip3</code>在安装Python3的时候是已经安装了的，如果不能正确执行命令，可能是Python3的安装不正确，可以重新安装。</li>
</ul>
<p>安装Python3的时候，安装包下载完成，但是在连接的时候出现如下错误：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Error: An unexpected error occurred during the `brew link` step</span><br><span class="line"></span><br><span class="line">The formula built, but is not symlinked into /usr/local</span><br><span class="line"></span><br><span class="line">Permission denied @ dir_s_mkdir - /usr/local/Frameworks</span><br><span class="line"></span><br><span class="line">Error: Permission denied @ dir_s_mkdir - /usr/local/Frameworks</span><br></pre></td></tr></table></figure>
<p>应该是在创建连接的时候没有权限发生了错误，因此依次执行一下：</p>
<ol>
<li><code>open /usr/local/Frameworks</code> 发现目录不存在</li>
<li><code>sudo mkdir /usr/local/Frameworks</code></li>
<li><code>sudo chown $(whoami):admin /usr/local/Frameworks</code></li>
<li><code>brew link python3</code></li>
</ol>
<p>安装Python3的命令：<code>brew install python3</code></p>
<h1 id="动手前需要知道"><a href="#动手前需要知道" class="headerlink" title="动手前需要知道"></a>动手前需要知道</h1><p>Referance：</p>
<ol>
<li><a href="https://cuiqingcai.com/927.html" target="_blank" rel="noopener">Python爬虫入门</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/21479334" target="_blank" rel="noopener">Python爬虫入门</a></li>
</ol>
<p>主要包含以下几个方面的知识点需要提前了解</p>
<ul>
<li>Python基础知识</li>
<li>Python中urllib和urllib2库的用法</li>
<li>Python正则表达式</li>
<li>URLError异常处理</li>
<li>Cookie使用</li>
</ul>
<p>在这里验证一个小的demo如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cookielib</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置保存cookie的文件，同级目录下的cookie.txt</span></span><br><span class="line">filename = <span class="string">'cookie.txt'</span></span><br><span class="line"><span class="comment">#声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件</span></span><br><span class="line">cookie = cookielib.MozillaCookieJar(filename)</span><br><span class="line"><span class="comment">#利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器</span></span><br><span class="line">handler = urllib2.HTTPCookieProcessor(cookie)</span><br><span class="line"><span class="comment">#通过handler来构建opener</span></span><br><span class="line">opener = urllib2.build_opener(handler)</span><br><span class="line"><span class="comment">#创建一个请求，原理同urllib2的urlopen</span></span><br><span class="line">response = opener.open(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line"><span class="comment">#保存cookie到文件</span></span><br><span class="line">cookie.save(ignore_discard=<span class="keyword">True</span>, ignore_expires=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>验证发现的问题：</p>
<ul>
<li><code>unresolved import &#39;urllib2&#39;</code><br>  发现在Python3中使用<code>urllib.request</code>代替<code>urllib2</code>，因此这里应该使用<code>import urllib.request</code>代替</li>
<li><code>unresolved import &#39;cookielib&#39;</code><br>  发现在Python3中使用<code>http.cookiejar</code>代替<code>cookielib</code>这个模块，因此这里应该使用<code>inmpor http.cookiejar</code>代替</li>
<li>两个参数：<ul>
<li>ignore_discard: save even cookies set to be discarded. </li>
<li>ignore_expires: save even cookies that have expiredThe file is overwritten if it already exists</li>
</ul>
</li>
</ul>
<h1 id="开始动手了！"><a href="#开始动手了！" class="headerlink" title="开始动手了！"></a>开始动手了！</h1><h2 id="糗百"><a href="#糗百" class="headerlink" title="糗百"></a>糗百</h2><p><a href="https://cuiqingcai.com/990.html" target="_blank" rel="noopener">Python爬虫实战一之爬取糗事百科段子</a></p>
<p>这里发现的问题：</p>
<ul>
<li>在Python3中打印函数的格式变成了<code>print()</code>，Python2中的格式是<code>print xx</code></li>
<li>在查询<code>user-agent</code>的<code>Mozilla</code>是什么意思的时候发现了这个有意思的图片：</li>
</ul>
<p><img src="/images/Python爬虫入门/Mozilla.png" alt="Mozilla的原因"></p>
<ul>
<li>这里正则表达式的理解花了一些时间：</li>
</ul>
<p><img src="/images/Python爬虫入门/正则表达式.png" alt="正则表达式语法"></p>
<p>最终的代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">page = <span class="number">1</span></span><br><span class="line">user_agent = <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span> : user_agent&#125;</span><br><span class="line"><span class="keyword">while</span> page &lt; <span class="number">100</span>:</span><br><span class="line">    url = <span class="string">'http://www.qiushibaike.com/hot/page/'</span> + str(page)</span><br><span class="line">    page = page + <span class="number">1</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        request = urllib.request.Request(url, headers = headers)</span><br><span class="line">        response = urllib.request.urlopen(request)</span><br><span class="line">        content = response.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">        <span class="comment"># 作者 内容 点赞数</span></span><br><span class="line">        pattern = re.compile(<span class="string">'&lt;div.*?clearfix"&gt;.*?&lt;h2&gt;(.*?)&lt;/h2&gt;.*?&lt;a.*?contentHerf".*?&lt;span&gt;(.*?)&lt;/span&gt;.*?stats".*?stats-vote".*?number"&gt;(.*?)&lt;/i&gt;'</span>,re.S)</span><br><span class="line">        items = re.findall(pattern, content)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            print(<span class="string">'作者：'</span> + item[<span class="number">0</span>] + <span class="string">'\n'</span> + <span class="string">'\n'</span> + <span class="string">'内容：'</span> + item[<span class="number">1</span>] + <span class="string">'\n'</span> + <span class="string">'点赞数：'</span> + item[<span class="number">2</span>] + <span class="string">'\n'</span>)</span><br><span class="line">    <span class="keyword">except</span> urllib.request.URLError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">if</span> hasattr(e, <span class="string">"code"</span>):</span><br><span class="line">            print(e.code)</span><br><span class="line">        <span class="keyword">if</span> hasattr(e, <span class="string">"reason"</span>):</span><br><span class="line">            print(e.reason)</span><br></pre></td></tr></table></figure>
<p>结社根据上述代码，进行面向对象模式的设计，进行代码的优化和封装：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QSBK</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        self.pageIndex = <span class="number">1</span></span><br><span class="line">        self.user_agent = <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span></span><br><span class="line">        self.headers = &#123;<span class="string">'User-Agent'</span> : self.user_agent&#125;</span><br><span class="line">        <span class="comment"># save content</span></span><br><span class="line">        self.stories = []</span><br><span class="line">        <span class="comment"># save the boolean value of whether continue the process</span></span><br><span class="line">        self.enable = <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">return</span> super().__init__(*args, **kwargs)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self, pageIndex)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            url = <span class="string">'http://www.qiushibaike.com/hot/page/'</span> + str(pageIndex)</span><br><span class="line">            request = urllib.request.Request(url,headers=self.headers)</span><br><span class="line">            response = urllib.request.urlopen(request)</span><br><span class="line">            pageCode = response.read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">            <span class="keyword">return</span> pageCode</span><br><span class="line">        <span class="keyword">except</span> urllib.request.URLError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="keyword">if</span> hasattr(e, <span class="string">"reason"</span>):</span><br><span class="line">                print(e.reason)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getPageItems</span><span class="params">(self, pageIndex)</span>:</span></span><br><span class="line">        pageCode = self.getPage(pageIndex)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pageCode:</span><br><span class="line">            print(<span class="string">"没有数据..."</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">        pattern = re.compile(<span class="string">'&lt;div.*?clearfix"&gt;.*?&lt;h2&gt;(.*?)&lt;/h2&gt;.*?&lt;a.*?contentHerf".*?&lt;span&gt;(.*?)&lt;/span&gt;.*?stats".*?stats-vote".*?number"&gt;(.*?)&lt;/i&gt;'</span>,re.S)</span><br><span class="line">        items = re.findall(pattern, pageCode)</span><br><span class="line">        pageStories = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            replaceBR = re.compile(<span class="string">'&lt;br/&gt;'</span>)</span><br><span class="line">            text = re.sub(replaceBR,<span class="string">"\n"</span>,item[<span class="number">1</span>])</span><br><span class="line">            pageStories.append([item[<span class="number">0</span>].strip(),text.strip(),item[<span class="number">2</span>].strip()])</span><br><span class="line">        <span class="keyword">return</span> pageStories</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.enable == <span class="keyword">True</span>:</span><br><span class="line">            <span class="keyword">if</span> len(self.stories) &lt; <span class="number">2</span>:</span><br><span class="line">                pageStories = self.getPageItems(self.pageIndex)</span><br><span class="line">                <span class="keyword">if</span> pageStories:</span><br><span class="line">                    self.stories.append(pageStories)</span><br><span class="line">                    self.pageIndex += <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getOneStory</span><span class="params">(self, pageStories, page)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> story <span class="keyword">in</span> pageStories:</span><br><span class="line">            <span class="comment"># wait for user input</span></span><br><span class="line">            inputContent = input()</span><br><span class="line">            self.loadPage()</span><br><span class="line">            <span class="keyword">if</span> inputContent == <span class="string">"Q"</span>:</span><br><span class="line">                self.enable = <span class="keyword">False</span></span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            print(<span class="string">"第%d页\n发布人：%s\n内容：%s\n赞：%s\n"</span> %(page, story[<span class="number">0</span>], story[<span class="number">1</span>], story[<span class="number">2</span>]))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"正在查看糗事百科，回车查看新的一条，Q退出"</span>)</span><br><span class="line">        self.enable = <span class="keyword">True</span></span><br><span class="line">        self.loadPage()</span><br><span class="line">        nowPage = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> self.enable:</span><br><span class="line">            <span class="keyword">if</span> len(self.stories)&gt;<span class="number">0</span>:</span><br><span class="line">                pageStories = self.stories[<span class="number">0</span>]</span><br><span class="line">                nowPage += <span class="number">1</span></span><br><span class="line">                <span class="keyword">del</span> self.stories[<span class="number">0</span>]</span><br><span class="line">                self.getOneStory(pageStories, nowPage)</span><br><span class="line">spider = QSBK()</span><br><span class="line">spider.start()</span><br></pre></td></tr></table></figure>
<p>发现的问题：</p>
<ul>
<li>python不用分号，因此一定要注意缩进位置，十分重要</li>
<li>Python3使用<code>input()</code>代替Python2中的<code>raw_input()</code>函数</li>
</ul>
<h2 id="百度贴吧"><a href="#百度贴吧" class="headerlink" title="百度贴吧"></a>百度贴吧</h2><p>目标：<a href="http://tieba.baidu.com/p/3138733512?see_lz=1&amp;pn=1" target="_blank" rel="noopener">纯原创我心中的NBA2014-2015赛季现役50大</a></p>

        </div>
      </div>
    </div>
  </div>
</article>



    <!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <p class="copyright text-muted">
          Theme By <a target="_blank" href="https://github.com/levblanc">Levblanc.</a>
          Inspired By <a target="_blank" href="https://github.com/klugjo/hexo-theme-clean-blog">Clean Blog.</a>
        <p class="copyright text-muted">
          Powered By <a target="_blank" href="https://hexo.io/">Hexo.</a>
        </p>
      </div>
    </div>
  </div>
</footer>


    <!-- After Footer Scripts -->
<script src="/js/highlight.pack.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function(event) {
    var codeBlocks = Array.prototype.slice.call(document.getElementsByTagName('pre'))
    codeBlocks.forEach(function(block, index) {
      hljs.highlightBlock(block);
    });
  });
</script>

  </body>
</html>

